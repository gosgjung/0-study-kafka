카프카는 이벤트 저장소로서... 이벤트가 저장된 위치를 기억할 수도 있고, 복구 또한 가능하다. 분산환경에서 사용할 수 있도록 브로커를 클러스터링하는 것 역시 가능하다. 다만 운영에 대한 노하우가 있어야 좋다.

래빗엠큐는 이벤트 큐잉 시스템이다. 분산처리환경에서 이벤트를 큐잉하기에 적합한 메시지 큐다. 지금은 가물가물하긴 한데 래빗엠큐는 메시지를 7만건까지만 큐잉가능하다. 7만건 이내에서 메시지를 소비할 수 있어야 한다. 래빗엠큐의 경우 컨슈머를 직접 잘 구현해야 하고, 데이터의 백업이나 복구 대책도 로컬이나 AWS S3를 사용하는 등의 수작업 개발들을 직접 손수 해야 한다.

래빗엠큐나 카프카를 사용할 때 메시지나 이벤트를 분산환경에서 큐잉해서 처리하면서 트래픽 처리를 분산처리하거나, 조금 오바하면 이벤트 지향적으로 강결합을 풀어내기 위해 내부 메시지 큐로 사용할수도 있다. 다만, 비동기적인 처리를 위해서는 아니지 않나 싶다. 그럴꺼면 모든 곳에 다 래빗엠큐 서버 붙이고 카프카 붙여서 쓰면 되지 않나 싶다. 

<br>

그런데... 카프카, 래빗엠큐를 사용하는 이유가 비동기처리 하나 만을 위해서라고 하는 사람을 봤다.

네트워크 통신의 물리적인 본질이 동기/블로킹이다보니 이것을 비동기적으로 감싼 것이 웹플럭스이고 WebClient인데 이 사람은 도대체 무슨 근거로 그런 이야기를 하는지 이해가 안갔었다.<br>

처음 [웹 플럭스를 공부할 때 봤었던 책](http://www.yes24.com/Product/Goods/101803558) 에서도 명시적으로 이야기한다. 메시징이라는 것 자체가 본질은 블로킹이고 webflux를 사용한다고 해서 비동기적인 처리를 하는 것은 아니라고.<br>

<br>



카프카, 래빗엠큐를 사용하는 이유가 비동기적인 처리 하나만을 위해서 사용한다는건 조금 그렇긴 했다.

예전에 주니어 개발자가 주식 데이터 서버를 인수인계 받으면서 새로운 기능을 추가했는데 이 분도 래빗엠큐의 메시지를 받는 @RabbitListener 가 비동기처리라고만 생각해서 리스너 로직에서 동기처리를 하는 DB인서트/웹소켓 MQ 푸시 로직을 그대로 추가했다. 결과적으로는 그 날 상용배포 후에 장애가 났었다. 

데이터가 굉장히 빠르게 몰려드는데, 블로킹 작업을 이벤트 리스너에서 사용하니 블로킹 작업의 처리속도와 처리량이 결국 이벤트 발급 속도, 이벤트 갯수를 물리적으로 못따라와서 장애가 난 거였다. 이런 경우 작업을 최소화 시키는 방법을 고안해야한다. 그리고 데이터를 어떻게 소비할지 고민해야 한다.  [아파치 카프카 애플리케이션 프로그래밍](http://www.yes24.com/Product/Goods/99122569)에서도 이런 데이터 처리시 보통 어떻게 처리하는지 살짝 힌트처럼 언급하는 부분을 보고 살짝 동감한 적이 있었다.<br>

이 당시에 코드리뷰에서도 **"리스너라고 해서 진짜 비동기가 아니다."** **"소비로직을 비동기적으로 처리해야 한다."** **"작업자 만드셔야 한다."** 그렇게 이야기도 했는데 끝까지 고집피워서 상용까지 배포가서 장애가 났었다. (난 분명히 이야기 했었다... 알고도 모른척하지 않았다. 다만 그 분이 고집이 엄청 셌던거였을 뿐...) <br>

<br>



