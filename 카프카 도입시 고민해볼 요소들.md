# 카프카 도입시 고민해볼 요소들



## 2023.01.19 

아직 카프카에 대해서는 강의와 예제 조금 돌려본 정도로 이해하고 있다. 그리고 배민 개발실에서의 [우아한 Tech - 분산이벤트 스트리밍](https://www.youtube.com/watch?v=PvAlbOm9WN8)에 대해서도 1.5번 들었다.<br>

에너지 모니터링 시스템 MQ 클라이언트 대응, 미국주식 데이터 처리 서버 개발 업무를 하면서 메시징 계열의 데이터 처리 서버 프로젝트를 했고, 데이터 처리 서버 프로젝트와 유사한 업무를 맡을 상황이 자주 있을 수도 있겠다는 생각을 했다. 그리고, 나도 매번 이런 메시징 업무만 하는게 아니라 REST API 나, 운영업무만 맡아서 하다보면 예전에 어떻게 해결했었고 뭐가 중요했는지 까먹을 상황이 분명히 올것 같다는 생각이 들었다. 그래서 조금 피곤해도 뭔가 카프카/MQ 사용시 주의해야 했던 점들을 조금씩 정리해두기로 결정했다.<br>

<br>



### 카프카/MQ 클러스터링이 작업 부하까지 해결해준다고 착각하지 말자.

에너지 모니터링 시스템에서 MQ 쪽 클라이언트, 전직장에서 미국주식 데이터 처리 서버 개발을 하면서는 전적으로 Active MQ, Rabbit MQ를 사용했다. 두 기술 모두 내 선택이 아니였고, 카프카 도입에 대해 이야기했으나 대부분 팀장레벨에서 Active MQ, RabbitMQ에 대한 무한한 신뢰로 인해 카프카를 도입하지는 못했었다.<br>

개인적인 견해는 이렇다. 카프카 도입을 하더라도 이벤트 스트리밍이 아닌 작업을 스트리밍 해버리면, 좋은 구조는 아닐것이라는 생각이 들었다. 미국주식 데이터 서버 개발 시에도 RabbitMQ를 통해 소켓 데이터(실시간 시세데이터)를 중계를 했지만, 이벤트의 개념이었다. 작업 큐로 MQ나 카프카의 큐를 사용하면 꽤 곤란해진다.<br>

<br>



#### MQ나 브로커를 작업 큐/작업 토픽으로 사용하면 안된다.

소프트웨어 적으로 작업 분배가 안되는 것은 내부의 생산자-소비자 모델을 적용한 소프트웨어 레벨에서의 작업 큐를 구현해서 처리해야 한다. 이 작업 큐를 처리하기 위해 클러스터링된 애플리케이션을 구현하거나, Docker,Kubernetes 기반의 구조로 스케일링이 가능하도록 구성해도 되지 않나 싶다.  [우아한 Tech - 분산이벤트 스트리밍](https://www.youtube.com/watch?v=PvAlbOm9WN8) 에서도 이 부분에 대해 언급해주고 계신다. 애플리케이션에서의 작업 클러스터링 로직은 직접 구현하셨다고 이야기 해주고 계신다. <br>

<br>



#### 데이터를 즉시 처리하지말고, 지연된 처리를 주기적으로 수행하게끔 코드 구조를 잡아가자

그리고 이렇게 하려면, 실시간으로 처리하는게 아니라 주기적으로 합계를 내리는 식으로 스케쥴러를 통한 주기적인 집계연산이 되게끔 해야 한다. 내 경우는 미국 주식데이터를 DB인서트 작업의 경우 15ms에 한번, 웹소켓 MQ로 푸시하는 작업의 경우 10ms 에 한번씩으로 스케쥴링 했었다. 이렇게 한 것은 캐시 Read/Write 속도, DB INSERT 속도 등을 모두 체크한 후에 내린 결정이었다. [우아한 Tech - 분산이벤트 스트리밍](https://www.youtube.com/watch?v=PvAlbOm9WN8) 에서도 1초에 한번씩 라이더님의 위치를 업데이트 하게끔 한다는 이야기를 들었는데, 내가 한 방식이 잘못된게 아니었구나 하는 생각이 들었다.<br>

<br>



#### 이벤트 발생속도에 비해 물리적인 작업 처리 속도/처리량이 따라가지 못할 경우

'데이터를 즉시 처리하지말고, 지연된 처리를 주기적으로 수행하게끔 코드 구조를 잡아가자' 에서 정리했듯 내부에서 작업을 로컬 큐를 이용해 작업을 클러스터링하는 로직을 개발해야 한다.<br>

카프카나 래빗엠큐를 작업큐로 사용하면 나중에 굉장히 곤란한 상황에 직면하게 된다.<br>

<br>



#### 레디스 외에도 로컬 큐를 마련해두자.

임시 작업 큐로 카피 온 라이트 기반의 작업 큐를 구성해야 한다면 인메모리 데이터 그리드 등을 적극적으로 활용하자. 레디스에 비해 인메모리 데이터 그리드를 서버 안에 두면, 레이턴시가 줄어든다. 작업이 유실될 것 같은 것은 카프카를 잘 사용한다면, 이벤트가 어디서 멈췄는지 오프셋을 통해 알 수 있다. 이벤트를 작업으로 변환하는 코드가 되어있다면, 작업으로 변환이 가능하다. 내 경우에도 레빗엠큐를 사용했지만, 이벤트(소켓데이터)에 대해 인서트 하는 작업은 별도의 자바 객체로 생성해 인메모리 데이터 그리드에 작업 큐로 저장해서 소비해서 사용했었다.

레디스를 작업 큐로 사용하는 것은 조금 문제가 있다. 레디스는 나름의 역할이 있다고 생각한다. 네트워크 레이턴시 문제도 있다. 이 부분에 대해서는 나도 명확하게 주장하지는 못하겠다. 레디스 신봉자들이 너무 많아서 이야기하면 꽤 골치아파지기에 몇번 포기했던것 같다.<br>

[우아한 Tech - 분산이벤트 스트리밍](https://www.youtube.com/watch?v=PvAlbOm9WN8) 에서도 비슷하게 로컬 캐시를 언급하시는데 이 이야기인 것 같다는 추측을 잠깐 했었다.<br>

<br>



### 카프카 토픽관리

이건 공부해야 할 것 같기는 하다.<br>

만약 1인 개발 체제이고 개발 기한이 굉장히 빠듯하고, 물리적으로 안되는 시간을 강압적으로 강요당한다면, 카프카보다는 레디스를 사용하는게 낫다. 하지만, 카프카를 사용할 수 있다면 카프카를 사용하는 게 나을 것 같다. 장애 발생시 멈췄던 지점부터 다시 시작하거나, 제일 첫 이벤트부터 다시 시작하도록 복구가 가능하기 때문이다.<br>

내 경우는 이벤트 발생 속도에 비해 작업의 처리량과 처리 속도가 느린 경우에 대해 처리하는 내부 생산자/소비자 로직을 경험해봤기에, 작업 처리 분산 로직은 처리로직 개발에는 개발 속도가 절감될 것이기에 비슷한 업무가 주어진다면 카프카를 선택하고 스터디하는 시간을 가지고 가지 않을까 싶다.<br>

<br>



### 카프카 스트림, 카프카 커넥트

정리 예정
