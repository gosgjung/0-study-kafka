# 카프카 컨슈머 사용해보기



일단 오늘 시간이 별로 없어서 설명하는 글 보다는 그냥 코드만 일일이 쭉 적어놓을 예정이다.나중에 다시 돌아와서 설명을 정리해놓든가 해야겠다.<br>



### 참고자료

- [@KafkaListener 를 이용한 Consumer 구현](https://jessyt.tistory.com/146)
  - 감사합니다 ㅠㅠ

<br>



### build.gradle 의존성 추가

```kotlin
implementation("org.springframework.kafka:spring-kafka")
```

<br>



### application.yml

```yaml
spring:
  kafka:
    producer:
      bootstrap-servers: localhost:9091, localhost:9092, localhost:9093
    consumer:
      bootstrap-servers: localhost:9091, localhost:9092, localhost:9093

```

<br>



### docker-compose

시간되면 나중에 추가





### KafkaEnvironments

토픽명이나 Listener 이름을 지정해놓는 상수들을 모아둔 클래스다. 

```kotlin
package io.study.kafkastreams.gosgjung.config.kafka

class KafkaEnvironements {

    companion object{
        const val TOPIC_NAME_SAMPLE1 = "SAMPLE_TOPIC_1"
        const val MESSAGE_LISTENER_NAME_SAMPLE1 = "messageListenerContainer"
        const val BATCH_LISTENER_NAME_SAMPLE1 = "batchListenerContainer"
    }

}
```







### Consumer

#### ListenerContainerFactory 빈 객체 생성/등록

```kotlin
package io.study.kafkastreams.gosgjung.config.kafka

import org.apache.kafka.clients.consumer.ConsumerConfig
import org.apache.kafka.common.serialization.StringDeserializer
import org.slf4j.Logger
import org.slf4j.LoggerFactory
import org.springframework.beans.factory.annotation.Value
import org.springframework.context.annotation.Bean
import org.springframework.context.annotation.Configuration
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory
import org.springframework.kafka.core.DefaultKafkaConsumerFactory
import org.springframework.kafka.listener.ContainerProperties

@Configuration
class KafkaConsumerConfig {

    @Value("\${spring.kafka.consumer.bootstrap-servers}")
    private lateinit var BOOTSTRAP_SERVERS: String

    private val logger: Logger = LoggerFactory.getLogger(javaClass)

    private fun kafkaConsumerProperties(): Map<String, Any> =
        mapOf(
            ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG to BOOTSTRAP_SERVERS,
            ConsumerConfig.AUTO_OFFSET_RESET_CONFIG to "latest", // 마지막 읽은 부분부터 조회
            ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG to false,
            ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG to StringDeserializer::class.java,
            ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG to StringDeserializer::class.java
        )

    @Bean(name = [KafkaEnvironements.MESSAGE_LISTENER_NAME_SAMPLE1])
    fun messageListenerContainer() : ConcurrentKafkaListenerContainerFactory<String, String> {
        val factory = ConcurrentKafkaListenerContainerFactory<String, String>()

        factory.setConcurrency(2)
        factory.consumerFactory = DefaultKafkaConsumerFactory(kafkaConsumerProperties())
        factory.containerProperties.pollTimeout = 500

        return factory
    }

}
```

<br>



### (1) 단순한 컨슈머

```kotlin
@Component
class Sample1Consumer {
    
    @KafkaListener(
        id = "sample1",
        topics = [KafkaEnvironements.TOPIC_NAME_SAMPLE1],
        clientIdPrefix = "sample1ClientId",
        containerFactory = KafkaEnvironements.MESSAGE_LISTENER_NAME_SAMPLE1,
        autoStartup = "\${listen.auto.start:true}", // 필요하면 추가하자.
        concurrency = "\${listen.concurrency:3}",   // 필요하면 추가하자.
    )
    fun listen1(received: String){
        logger.info("received = $received")
    }
    
}
```

윽... 설명 몇가지는 나중에 추가할 예정 ... 흐...<br>

<br>



### (2) partition 을 지정해서 리슨하기

```kotlin
@Component
class Sample1Consumer{
    @KafkaListener(
        id = "sample1",
        topics = [KafkaEnvironements.TOPIC_NAME_SAMPLE1],
        clientIdPrefix = "sample1ClientId",
        containerFactory = KafkaEnvironements.MESSAGE_LISTENER_NAME_SAMPLE1,
        autoStartup = "\${listen.auto.start:true}", // 필요하면 추가하자.
        concurrency = "\${listen.concurrency:3}",   // 필요하면 추가하자.
        // 특정 파티션의 레코드만 listen 하려고 할 경우는 아래와 같이 partitions = ["0"] 처럼 지정해준다.
         topicPartitions = [TopicPartition(topic = KafkaEnvironements.TOPIC_NAME_SAMPLE1, partitions = ["0"])],
    )
    fun listen2(received: String){
        logger.info("received = $received")
    }
}
```

<br>



### (3) initialOffset - 처음 읽어들일 위치(offset)를 지정한다.

```kotlin
@Component
class Sample1Consumer{
    @KafkaListener(
        id = "sample1",
        topics = [KafkaEnvironements.TOPIC_NAME_SAMPLE1],
        clientIdPrefix = "sample1ClientId",
        containerFactory = KafkaEnvironements.MESSAGE_LISTENER_NAME_SAMPLE1,
        autoStartup = "\${listen.auto.start:true}", // 필요하면 추가하자.
        concurrency = "\${listen.concurrency:3}",   // 필요하면 추가하자.
        // 어디부터 읽어들일지 명시하고 싶다면 아래와 같이 initialOffset 을 지정해주자.
        topicPartitions = [
            TopicPartition(
                topic = KafkaEnvironements.MESSAGE_LISTENER_NAME_SAMPLE1,
                partitions = ["1"],
                // initialOffset 을 통해 어디부터 읽어들이지 명시했다.
                partitionOffsets = [PartitionOffset(partition = "0", initialOffset = "5000")]
             )
         ]
    )
    fun listen3(received: String){
        logger.info("received = $received")
    }
}
```

<br>



### (4) ack = MANUAL 로 세팅, 클라이언트 로직인 @KafkaListener 에서 수동으로 커밋해줘야 한다.

```kotlin
@Component
class Sample1Consumer{
    // ACK 모드를 MANUAL 로 세팅했을 경우
    // 메서드의 파라미터에 Acknowledgement 를 추가해준다.
    @KafkaListener(
        id = "sample1",
        topics = [KafkaEnvironements.TOPIC_NAME_SAMPLE1],
        clientIdPrefix = "sample1ClientId",
        containerFactory = KafkaEnvironements.MESSAGE_LISTENER_NAME_SAMPLE1,
        autoStartup = "\${listen.auto.start:true}", // 필요하면 추가하자.
        concurrency = "\${listen.concurrency:3}",   // 필요하면 추가하자.
    )
    fun listen4(received: String, ack: Acknowledgment){     // ACK 모드를 MANUAL 로 세팅했을 경우
                                                            // @KafkaListener 메서드에서는 ack: Acknowledgment 를 인자로 받게끔 해준다.
        logger.info("received = $received")
        ack.acknowledge() // 오프셋을 커밋한다.
    }
}
```

<br>



### 참고) 레코드의 메타 데이터를 가져오는 방식 2가지

레코드의 메타데이터를 가져오는 방식은 2가지가 있다.

- 1\) @Payload, @Header 를 이용하는 방식
- 2\) ConsumerRecordMetadata 객체를 이용하는 방식

<br>



### (5.1) @Payload, @Header - 레코드의 메타데이터를 각각 받아오기

```kotlin
@Component
class Sample1Consumer{
    // (5)
    /// 레코드의 메타 데이터를 가져오는 방식
    // = (1) @Payload, @Header 를 이용하는 방식
    // = (2) ConsumerRecordMetadata 객체를 이용하는 방법
    
    // 레코드의 메타 데이터를 가져오는 방식 (1) @Payload, @Header 를 이용하는 방식
    @KafkaListener(
        id = "sample1",
        topics = [KafkaEnvironements.TOPIC_NAME_SAMPLE1],
        clientIdPrefix = "sample1ClientId",
        containerFactory = KafkaEnvironements.MESSAGE_LISTENER_NAME_SAMPLE1,
        autoStartup = "\${listen.auto.start:true}", // 필요하면 추가하자.
        concurrency = "\${listen.concurrency:3}",   // 필요하면 추가하자.
    )
    fun listen5(
        @Payload received: String,
        @Header(KafkaHeaders.RECEIVED_MESSAGE_KEY, required = false) key: Int?,
        @Header(KafkaHeaders.RECEIVED_PARTITION_ID) partition: Int,
        @Header(KafkaHeaders.RECEIVED_TOPIC) topic: String,
        @Header(KafkaHeaders.RECEIVED_TIMESTAMP) timestamp: Long
    ){
        logger.info("data = $received, key = $key, partition = $partition, topic = $topic, timestamp = $timestamp")
    }
}
```

<br>



### (5.2) ConsumerRecordMetadata 객체를 이용하는 방법

```kotlin
@Component
class Sample1Consumer{
    // 레코드의 메타 데이터를 가져오는 방식 (2) ConsumerRecordMetadata 객체를 이용하는 방식
    @KafkaListener(
        id = "sample1",
        topics = [KafkaEnvironements.TOPIC_NAME_SAMPLE1],
        clientIdPrefix = "sample1ClientId",
        containerFactory = KafkaEnvironements.MESSAGE_LISTENER_NAME_SAMPLE1,
        autoStartup = "\${listen.auto.start:true}", // 필요하면 추가하자.
        concurrency = "\${listen.concurrency:3}",   // 필요하면 추가하자.
    )
    fun listen6(
        recived: String, meta: ConsumerRecordMetadata
    ){
        logger.info("data = $recived, partition = ${meta.partition()}, topic = ${meta.topic()}, timestamp = ${meta.timestamp()}")
    }
}
```

<br>



### (6) Batch 기반으로 Listen 하기

Batch 기반으로 Listen 하기 위해서는 먼저 Batch 방식으로 리슨할 containerFactory 를 선언해야 한다.<br>



#### KafkaListenerContainerFactory 를 Bean 으로 선언/정의

```kotlin
@Configuration
class KafkaConsumerConfig {

    @Value("\${spring.kafka.consumer.bootstrap-servers}")
    private lateinit var BOOTSTRAP_SERVERS: String

    private val logger: Logger = LoggerFactory.getLogger(javaClass)

    private fun kafkaConsumerProperties(): Map<String, Any> =
        mapOf(
            ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG to BOOTSTRAP_SERVERS,
            ConsumerConfig.AUTO_OFFSET_RESET_CONFIG to "latest", // 마지막 읽은 부분부터 조회
            ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG to false,
            ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG to StringDeserializer::class.java,
            ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG to StringDeserializer::class.java
        )
    
    @Bean(name = [KafkaEnvironements.BATCH_LISTENER_NAME_SAMPLE1])
    fun batchListenerFactory() : ConcurrentKafkaListenerContainerFactory<String, String>{
        val factory = ConcurrentKafkaListenerContainerFactory<String, String>()
        factory.setConcurrency(3)
        factory.consumerFactory = DefaultKafkaConsumerFactory(kafkaConsumerProperties())
        factory.containerProperties.pollTimeout = 500
        factory.isBatchListener = true // 이 부분이 배치 설정하는 부분이다.
        return factory
    }
}
```



ListenerContainerFactory 객체를 빈으로 생성시 배치 방식의 리스너로 스프링 컨테이너에 등록하려면 ListenerContainerFactory 객체 내의 isBatchListener 필드를 true 로 세팅해준다.<br>

(batchListener인지 여부를 true로 세팅)<br>



#### (6.1) 단순 batch 리슨

```kotlin
@Configuration
class KafkaConsumerConfig {

    @Value("\${spring.kafka.consumer.bootstrap-servers}")
    private lateinit var BOOTSTRAP_SERVERS: String

    private val logger: Logger = LoggerFactory.getLogger(javaClass)
    
    // (1) batch 1
    @KafkaListener(
        id = "sample1",
        topics = [KafkaEnvironements.TOPIC_NAME_SAMPLE1],
        clientIdPrefix = "sample1ClientId",
        containerFactory = KafkaEnvironements.BATCH_LISTENER_NAME_SAMPLE1,
        autoStartup = "\${listen.auto.start:true}", // 필요하면 추가하자.
        concurrency = "\${listen.concurrency:3}",   // 필요하면 추가하자.
    )
    fun listen7(recieved: List<String>){ // 1)
        println("received : $recieved")
    }
    
}
```



1\) 

- `fun listen7(received: List<String>){...}`  에서 정의했듯 `List<String>` 과 같은 타입으로 파라미터를 세팅해주면 된다.

<br>



#### (6.2) K,V가 아닌 Message 타입의 리스트로 받아보기

```kotlin
@Configuration
class KafkaConsumerConfig {

    @Value("\${spring.kafka.consumer.bootstrap-servers}")
    private lateinit var BOOTSTRAP_SERVERS: String

    private val logger: Logger = LoggerFactory.getLogger(javaClass)
    
    // (2) Message 의 List (List<Message> 로 데이터를 받는 방식)
    @KafkaListener(
        id = "sample1",
        topics = [KafkaEnvironements.TOPIC_NAME_SAMPLE1],
        clientIdPrefix = "sample1ClientId",
        containerFactory = KafkaEnvironements.BATCH_LISTENER_NAME_SAMPLE1,
        autoStartup = "\${listen.auto.start:true}", // 필요하면 추가하자.
        concurrency = "\${listen.concurrency:3}",   // 필요하면 추가하자.
    )
    fun listen8(received: List<Message>){ // 1)
        println("received : $received")
    }
    
}
```



1\) 

- `fun listen8(received: List<Message>){...}`  에서 정의했듯 `List<Message>` 과 같은 타입으로 파라미터를 세팅해주면 된다.



#### (6.3) nullable 한 `List<Message>` 로 데이터 받기

```kotlin
@Configuration
class KafkaConsumerConfig {

    @Value("\${spring.kafka.consumer.bootstrap-servers}")
    private lateinit var BOOTSTRAP_SERVERS: String

    private val logger: Logger = LoggerFactory.getLogger(javaClass)
    
    // (3) nullable 한 List<Message> 로 데이터 받기
    @KafkaListener(
        id = "sample1",
        topics = [KafkaEnvironements.TOPIC_NAME_SAMPLE1],
        clientIdPrefix = "sample1ClientId",
        containerFactory = KafkaEnvironements.BATCH_LISTENER_NAME_SAMPLE1,
        autoStartup = "\${listen.auto.start:true}", // 필요하면 추가하자.
        concurrency = "\${listen.concurrency:3}",   // 필요하면 추가하자.
    )
    fun listen9(received: List<Message>?){ // 1)
        println("received : $received")
    }
    
}
```



1\) 

- `fun listen9(received: List<Message>?){...}`  에서 정의했듯 `List<Message>?` 과 같은 타입으로 파라미터를 세팅해주면 된다.



#### (6.4) ack 모드 = MANUAL 로 배치 데이터 리슨하기

batchListener에 별도의 설정을 해줘야한다.

설정코드

```kotlin
@Configuration
class KafkaConsumerConfig {

    @Value("\${spring.kafka.consumer.bootstrap-servers}")
    private lateinit var BOOTSTRAP_SERVERS: String

    private val logger: Logger = LoggerFactory.getLogger(javaClass)
    
    private fun kafkaConsumerProperties(): Map<String, Any> =
        mapOf(
            ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG to BOOTSTRAP_SERVERS,
            ConsumerConfig.AUTO_OFFSET_RESET_CONFIG to "latest", // 마지막 읽은 부분부터 조회
            ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG to false,
            ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG to StringDeserializer::class.java,
            ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG to StringDeserializer::class.java
        )
    
    // ...
    
    @Bean(name = [KafkaEnvironements.BATCH_LISTENER_NAME_SAMPLE1])
    fun batchListenerFactory() : ConcurrentKafkaListenerContainerFactory<String, String>{
        val factory = ConcurrentKafkaListenerContainerFactory<String, String>()
        factory.setConcurrency(3)
        factory.consumerFactory = DefaultKafkaConsumerFactory(kafkaConsumerProperties())
        factory.containerProperties.pollTimeout = 500
        factory.containerProperties.ackMode = ContainerProperties.AckMode.MANUAL // 1)
        factory.isBatchListener = true
        return factory
    }
}
```



1\) 

- `factory.containerProperties.ackMode = ContainerProperties.AckMode.MANUAL`  
- containerProperties 필드의 ackMode 프로퍼티를 ContainerProperties.AckMode.MANUAL 로 세팅해준다.



@KafkaListener 코드

```kotlin
@Configuration
class KafkaConsumerConfig {

    @Value("\${spring.kafka.consumer.bootstrap-servers}")
    private lateinit var BOOTSTRAP_SERVERS: String

    private val logger: Logger = LoggerFactory.getLogger(javaClass)
    
    private fun kafkaConsumerProperties(): Map<String, Any> =
        mapOf(
            ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG to BOOTSTRAP_SERVERS,
            ConsumerConfig.AUTO_OFFSET_RESET_CONFIG to "latest", // 마지막 읽은 부분부터 조회
            ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG to false,
            ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG to StringDeserializer::class.java,
            ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG to StringDeserializer::class.java
        )
    
    // (4) ack 모드 = MANUAL 로 데이터 받기.
    // batchMessageListener 컨피그에 별도의 설정을 해줘야 한다.
    // 코드에서는 Acknowledgement 객체를 메서드의 파라미터로 지정해줘야 한다.
    @KafkaListener(
        id = "sample1",
        topics = [KafkaEnvironements.TOPIC_NAME_SAMPLE1],
        clientIdPrefix = "sample1ClientId",
        containerFactory = KafkaEnvironements.BATCH_LISTENER_NAME_SAMPLE1,
        autoStartup = "\${listen.auto.start:true}", // 필요하면 추가하자.
        concurrency = "\${listen.concurrency:3}",   // 필요하면 추가하자.
    )
    fun listen10(received: List<Message>?, acknowledgement: Acknowledgment){
        println("received : $received")
        acknowledgement.acknowledge()
    }
    
}
```

<br>



#### (6.5) 배치데이터 LISTEN 시 `Consumer<K,V>` 도 함께 받기

```kotlin
@Configuration
class KafkaConsumerConfig {

    @Value("\${spring.kafka.consumer.bootstrap-servers}")
    private lateinit var BOOTSTRAP_SERVERS: String

    private val logger: Logger = LoggerFactory.getLogger(javaClass)
    
    private fun kafkaConsumerProperties(): Map<String, Any> =
        mapOf(
            ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG to BOOTSTRAP_SERVERS,
            ConsumerConfig.AUTO_OFFSET_RESET_CONFIG to "latest", // 마지막 읽은 부분부터 조회
            ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG to false,
            ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG to StringDeserializer::class.java,
            ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG to StringDeserializer::class.java
        )
    
    // (5) Consumer<K,V> 도 함께 받기
    @KafkaListener(
        id = "sample1",
        topics = [KafkaEnvironements.TOPIC_NAME_SAMPLE1],
        clientIdPrefix = "sample1ClientId",
        containerFactory = KafkaEnvironements.BATCH_LISTENER_NAME_SAMPLE1,
        autoStartup = "\${listen.auto.start:true}", // 필요하면 추가하자.
        concurrency = "\${listen.concurrency:3}",   // 필요하면 추가하자.
    )
    fun listen11(received: List<Message>?, acknowledgement: Acknowledgment, consumer: Consumer<String, String>){
        println("received : $received")
        acknowledgement.acknowledge()
    }
}
```



#### (6.6) 배치 데이터 리슨 시 List<ConsumerRecord\<K,V\> 로 리슨하기

```kotlin
@Configuration
class KafkaConsumerConfig {

    @Value("\${spring.kafka.consumer.bootstrap-servers}")
    private lateinit var BOOTSTRAP_SERVERS: String

    private val logger: Logger = LoggerFactory.getLogger(javaClass)
    
    private fun kafkaConsumerProperties(): Map<String, Any> =
        mapOf(
            ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG to BOOTSTRAP_SERVERS,
            ConsumerConfig.AUTO_OFFSET_RESET_CONFIG to "latest", // 마지막 읽은 부분부터 조회
            ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG to false,
            ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG to StringDeserializer::class.java,
            ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG to StringDeserializer::class.java
        )
    
    // (6) ConsumerRecord의 List로 데이터 받기
    // = List<ConsumerRecord<String, String>>
    @KafkaListener(
        id = "sample1",
        topics = [KafkaEnvironements.TOPIC_NAME_SAMPLE1],
        clientIdPrefix = "sample1ClientId",
        containerFactory = KafkaEnvironements.BATCH_LISTENER_NAME_SAMPLE1,
        autoStartup = "\${listen.auto.start:true}", // 필요하면 추가하자.
        concurrency = "\${listen.concurrency:3}",   // 필요하면 추가하자.
    )
    fun listen12(received: List<ConsumerRecord<String, String>>){
        received.forEach{
            println("batch data :: ${it.value()} topic = ${it.topic()} partition = ${it.partition()}, offset = ${it.offset()}")
        }
    }
}
```

<br>



#### 배치 데이터 리슨 시 List\<Consumer<K, V\>\>, Acknowledgment 를 함께 받기

```kotlin
@Configuration
class KafkaConsumerConfig {

    @Value("\${spring.kafka.consumer.bootstrap-servers}")
    private lateinit var BOOTSTRAP_SERVERS: String

    private val logger: Logger = LoggerFactory.getLogger(javaClass)
    
    private fun kafkaConsumerProperties(): Map<String, Any> =
        mapOf(
            ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG to BOOTSTRAP_SERVERS,
            ConsumerConfig.AUTO_OFFSET_RESET_CONFIG to "latest", // 마지막 읽은 부분부터 조회
            ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG to false,
            ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG to StringDeserializer::class.java,
            ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG to StringDeserializer::class.java
        )
    
    // (7) List<Consumer<K,V>> 와 Acknowledgement 도 함께 받기
    @KafkaListener(
        id = "sample1",
        topics = [KafkaEnvironements.TOPIC_NAME_SAMPLE1],
        clientIdPrefix = "sample1ClientId",
        containerFactory = KafkaEnvironements.BATCH_LISTENER_NAME_SAMPLE1,
        autoStartup = "\${listen.auto.start:true}", // 필요하면 추가하자.
        concurrency = "\${listen.concurrency:3}",   // 필요하면 추가하자.
    )
    fun listen13(received: List<ConsumerRecord<String, String>>, acknowledgment: Acknowledgment){
        received.forEach{
            println("batch data :: ${it.value()} topic = ${it.topic()} partition = ${it.partition()}, offset = ${it.offset()}")
            acknowledgment.acknowledge()
        }
    }
}
```

<br>



### (7) GroupId 를 지정해서 Listen 하는 방식

GroupId=1 에 대한 @KafkaListener 메서드 들에 컨슈머 1, 컨슈머 2가 지정되어 있고,
GroupId=2 에 대한 @KafkaListener 메서드 들에 컨슈머 3, 컨슈머 4가 지정되어 있다고 해보자.

<br>

이때

- GroupId = 1 에 데이터가 들어오면, 컨슈머 1, 컨슈머 2 둘 중 하나만 실행되고
- GroupId = 2 에 데이터가 들어오면, 컨슈머 3, 컨슈머 4 둘 중 하나만 실행된다.

<br>



이미지 출처 : [@KafkaListener 를 이용한 Consumer 구현](https://jessyt.tistory.com/146)

![1](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdkluKq%2Fbtrc7mEuFQ2%2FPqrtWpZavolJ8vxrpTL7K1%2Fimg.png)

<br>



```kotlin
@Configuration
class KafkaConsumerConfig {

    @Value("\${spring.kafka.consumer.bootstrap-servers}")
    private lateinit var BOOTSTRAP_SERVERS: String

    private val logger: Logger = LoggerFactory.getLogger(javaClass)
    
    private fun kafkaConsumerProperties(): Map<String, Any> =
        mapOf(
            ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG to BOOTSTRAP_SERVERS,
            ConsumerConfig.AUTO_OFFSET_RESET_CONFIG to "latest", // 마지막 읽은 부분부터 조회
            ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG to false,
            ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG to StringDeserializer::class.java,
            ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG to StringDeserializer::class.java
        )
    
    /// GroupId 지정해서 Listen 하는 방식
    // GroupId=1 에 대한 @KafkaListener 메서드 들에 컨슈머 1, 컨슈머 2가 지정되어 있고,
    // GroupId=2 에 대한 @KafkaListener 메서드 들에 컨슈머 3, 컨슈머 4가 지정되어 있다고 해보자.
    // 이때
    // GroupId = 1 에 데이터가 들어오면, 컨슈머 1, 컨슈머 2 둘 중 하나만 실행되고
    // GroupId = 2 에 데이터가 들어오면, 컨슈머 3, 컨슈머 4 둘 중 하나만 실행된다.
    @KafkaListener(id = "listener1", topics = [KafkaEnvironements.TOPIC_NAME_SAMPLE1], groupId = "group1")
    fun listener1(received: String){
        println("listener1 >>> received = $received")
    }

    @KafkaListener(id = "listener2", topics = [KafkaEnvironements.TOPIC_NAME_SAMPLE1], groupId = "group1")
    fun listener2(received: String){
        println("listener2 >>> received = $received")
    }

    @KafkaListener(id = "listener3", topics = [KafkaEnvironements.TOPIC_NAME_SAMPLE1], groupId = "group2")
    fun listener3(received: String){
        println("listener3 >>> received = $received")
    }

    @KafkaListener(id = "listener4", topics = [KafkaEnvironements.TOPIC_NAME_SAMPLE1], groupId = "group2")
    fun listener4(received: String){
        println("listener4 >>> received = $received")
    }
}
```



